{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 誤差逆伝搬法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('deep-learning-from-scratch')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レイヤの実装\n",
    "\n",
    "レイヤは順伝搬のforward() と逆伝搬のbackward()を実装する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 乗算レイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        return x * y\n",
    "        \n",
    "        \n",
    "    def backward(self, dout):\n",
    "        \"\"\"\n",
    "        dout: 上流から伝わってきた微分\n",
    "        \"\"\"\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x        \n",
    "        return dx, dy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple: 2.2 AppleNum: 110.00000000000001 Tax:  200\n"
     ]
    }
   ],
   "source": [
    "dprice = 1\n",
    "d_apple_price, d_tax = mul_tax_layer.backward(dprice)\n",
    "d_apple, d_apple_num = mul_apple_layer.backward(d_apple_price)\n",
    "print(\"Apple:\", d_apple, \"AppleNum:\", d_apple_num, \"Tax: \", d_tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        return x + y\n",
    "        \n",
    "    def backward(self, dout):\n",
    "        \"\"\"\n",
    "        dout: 上流から伝わってきた微分\n",
    "        \"\"\"\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        return dx, dy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price: 715\n",
      "dApple: 2.2\n",
      "dApple_num: 110\n",
      "dOrange: 3.3000000000000003\n",
      "dOrange_num: 165\n",
      "dTax: 650\n"
     ]
    }
   ],
   "source": [
    "# りんご２つ　と　みかん３つ　の買い物\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "# layer\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)  # (1)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num)  # (2)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price)  # (3)\n",
    "price = mul_tax_layer.forward(all_price, tax)  # (4)\n",
    "\n",
    "# backward\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)  # (4)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)  # (3)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)  # (2)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)  # (1)\n",
    "\n",
    "print(\"price:\", int(price))\n",
    "print(\"dApple:\", dapple)\n",
    "print(\"dApple_num:\", int(dapple_num))\n",
    "print(\"dOrange:\", dorange)\n",
    "print(\"dOrange_num:\", int(dorange_num))\n",
    "print(\"dTax:\", dtax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self_mask] = 0\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW =  np.dot(self.x.T, dout)\n",
    "        self.db = cp.sum(dout, axis = 0)\n",
    "        return self.dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from common.functions import cross_entropy_error, softmax\n",
    "class softmaxWthLoss:\n",
    "    def __init__(self):\n",
    "        self.loss =None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 誤差逆伝搬法の実装\n",
    "\n",
    "ニューラルネットワーク学習の全体図"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # Weight / Bias 初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"各レイヤへ伝搬\"\"\"\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    # x:入力データ, t:教師データ\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"損失関数\"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x:入力データ, t:教師データ\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"重みパラメータに対する勾配を誤差逆伝搬法によって求める\"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:2.66482928601e-13\n",
      "b1:8.52096255968e-13\n",
      "W2:8.83539676656e-13\n",
      "b2:1.19904083884e-10\n"
     ]
    }
   ],
   "source": [
    "from dataset.mnist import load_mnist\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "n = 3\n",
    "x_batch = x_train[:n]\n",
    "t_batch = t_train[:n]\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "# 各重みの絶対誤差の平均を求める\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) ) \n",
    "    print(key + \":\" + str(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 誤差逆伝搬法を使った学習\n",
    "\n",
    "誤差逆伝搬を使うことによって、効率よく勾配を求めることができる。  \n",
    "※4章でnumerical_gradientはおそすぎて話にならなかった・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10918f400>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10918fa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CopyFrom 4\n",
    "\n",
    "\"\"\"\n",
    "ハイパーパラメータ\n",
    "\"\"\"\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list=[]\n",
    "# 1エポックあたりの　繰り返しの数\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num): # ミニバッチの取得\n",
    "\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    # 勾配の計算\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # パラメータの更新\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "            network.params[key] -= learning_rate * grad[key]\n",
    "            \n",
    "    # 学習経過の記録\n",
    "    loss = network.loss(x_batch, t_batch) \n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train) # 訓練データ自体の認識精度\n",
    "        test_acc = network.accuracy(x_test, t_test) # テストデータの認識精度\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "plt.plot(train_acc_list)\n",
    "plt.plot(test_acc_list, linestyle='--')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
